{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with h5py.File(\"data02/london_lite_gt.h5\",\"r\") as f:\n",
    "    fovs = f[\"fov\"][:]\n",
    "    sim = f[\"sim\"][:].astype(np.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def bag_of_words(centroids, img_descriptors):\n",
    "    n_centroids = centroids.shape[0]  # number of centroids found with the KMeans clustering\n",
    "    n_descriptors = img_descriptors.shape[0]  # number of descriptors extracted from the image\n",
    "\n",
    "    bow_vector = np.zeros(n_centroids)\n",
    "\n",
    "    for i in range(n_descriptors):\n",
    "        idx = np.argmin(np.linalg.norm(centroids - img_descriptors[i], axis=1), axis=0)\n",
    "        bow_vector[idx] += 1\n",
    "    return bow_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, json_path, transform=None):\n",
    "        self.transform=transform\n",
    "        self.root_dir = root_dir\n",
    "        with open(json_path,\"r\") as f:\n",
    "            m_idx = json.load(f)\n",
    "            self.m_imgs = np.array(m_idx[\"im_paths\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.m_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = plt.imread(os.path.join(self.root_dir, self.m_imgs[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device: cuda\n"
     ]
    }
   ],
   "source": [
    "# def create_deep_descriptors():\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Loaded device: {device}\")\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding centroids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koend\\AppData\\Local\\Temp\\ipykernel_25536\\2551632580.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for img in tqdm_notebook(loader):\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a45523dce81e4434b6781b22175437c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     18\u001B[0m         output \u001B[38;5;241m=\u001B[39m model(img)\n\u001B[1;32m---> 20\u001B[0m         \u001B[43mkmeans\u001B[49m\u001B[38;5;241m.\u001B[39mpartial_fit(output\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()[:, :, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     22\u001B[0m centroids \u001B[38;5;241m=\u001B[39m kmeans\u001B[38;5;241m.\u001B[39mcluster_centers_\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Create BoVW vectors\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[25], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     18\u001B[0m         output \u001B[38;5;241m=\u001B[39m model(img)\n\u001B[1;32m---> 20\u001B[0m         \u001B[43mkmeans\u001B[49m\u001B[38;5;241m.\u001B[39mpartial_fit(output\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()[:, :, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     22\u001B[0m centroids \u001B[38;5;241m=\u001B[39m kmeans\u001B[38;5;241m.\u001B[39mcluster_centers_\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Create BoVW vectors\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:930\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:921\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256), antialias=False)\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "database = CustomDataset(root_dir=\"data02\", json_path=\"data02/database/database_lite.json\", transform=transform)\n",
    "loader = DataLoader(database, batch_size=batch_size)\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=32, random_state=0, batch_size=batch_size, n_init=3)\n",
    "\n",
    "# Find centroids\n",
    "print(\"Finding centroids...\")\n",
    "for img in tqdm_notebook(loader):\n",
    "    img = img.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "\n",
    "        kmeans.partial_fit(output.cpu().numpy()[:, :, 0, 0])\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Create BoVW vectors\n",
    "print(\"Finding centroids...\")\n",
    "bow_map_images = None\n",
    "for img in tqdm_notebook(loader):\n",
    "    img = img.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        for i_batch in range(output.shape[0]):\n",
    "            bow = bag_of_words(centroids, output.cpu().numpy()[i_batch, :, 0, 0])\n",
    "            if bow_map_images is None:\n",
    "                bow_map_images = bow\n",
    "            else:\n",
    "                bow_map_images = np.vstack( (bow_map_images, bow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_image(img, n):\n",
    "    print(\"split\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}